{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Downloading mitocheck traiing data\n",
                "\n",
                "In this notebook, we are acquiring the MitoCheck dataset from the [MitoCheck Data repository](https://github.com/WayScience/mitocheck_data). \n",
                "We will specifically download the [training dataset](https://github.com/wayscience/mitocheck_data/blob/main/3.normalize_data/normalized_data/training_data.csv.gz) and the control dataset.\n",
                "\n",
                "The downloaded datasets will be saved in the `./raw` folder, designated for storing all raw datasets within this repository.\n",
                "\n",
                "Data information:\n",
                "\n",
                "- negative_control_data/ : Nuclei features from negative control cells transfected with scrambled siRNA.\n",
                "- positive_control_data/ : Nuclei features from positive control cells transfected with siRNA targeting genes used during mitosis (INCENP, KIF11, COPB1).\n",
                "- training_data/ : Nuclei features from cells manually labeled with a phenotypic class by MitoCheck Consortium.\n",
                "\n",
                "More information can be found [here](https://zenodo.org/records/7967386)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pathlib\n",
                "import logging\n",
                "import zipfile\n",
                "\n",
                "import requests"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# downloading the data\n",
                "log_file_name = pathlib.Path(\"download_log.log\")\n",
                "chunk_size_download = 81920\n",
                "control_url = \"\"\n",
                "train_url = \"https://github.com/wayscience/mitocheck_data/raw/main/3.normalize_data/normalized_data/training_data.csv.gz\"\n",
                "control_url = \"https://zenodo.org/records/7967386/files/3.normalize_data__normalized_data.zip?download=1\"\n",
                "\n",
                "# output paths\n",
                "raw_dir = pathlib.Path(\"./raw/\").resolve(strict=True)\n",
                "train_outname = train_url.split(\"/\")[-1]\n",
                "control_out_path = raw_dir / \"3.normalized_data.zip\"\n",
                "train_out_path = raw_dir / train_outname\n",
                "control_unzip_path = raw_dir / \"normalized_data\"\n",
                "\n",
                "\n",
                "# setting up logger\n",
                "logging.basicConfig(\n",
                "    filename=log_file_name,\n",
                "    level=logging.DEBUG,\n",
                "    format=\"%(levelname)s:%(asctime)s:%(name)s:%(message)s\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "# downloading training data using requests\n",
                "logging.info(f\"Downloading trianing set data from: {train_url}\")\n",
                "with requests.get(train_url, stream=True) as r:\n",
                "\n",
                "    # raise error if the there's an error\n",
                "    r.raise_for_status()\n",
                "    logging.info(f\"Downloading training dataset: {r.headers.get('Content-Length')}MB\")\n",
                "\n",
                "    # creating a file to write the downloaded contents in chunks\n",
                "    with open(train_out_path, mode=\"wb\") as out_file:\n",
                "        for chunk in r.iter_content(chunk_size=chunk_size_download):\n",
                "            out_file.write(chunk)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# downloading control data using requests\n",
                "logging.info(f\"Downloading control dataset from: {train_url}\")\n",
                "with requests.get(control_url, stream=True) as r:\n",
                "\n",
                "    # raise error if the there's an error\n",
                "    r.raise_for_status()\n",
                "    logging.info(f\"Downloading control dataset: {r.headers.get('Content-Length')}MB\")\n",
                "\n",
                "    # creating a file to write the downloaded contents in chunks\n",
                "    with open(control_out_path, mode=\"wb\") as out_file:\n",
                "        for chunk in r.iter_content(chunk_size=1024**2):\n",
                "            out_file.write(chunk)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# next is to unzip the control dataset inside the raw data folder\n",
                "logging.info(f\"Unzipping control dataset into: {raw_dir}\")\n",
                "with zipfile.ZipFile(control_out_path, mode=\"r\") as zip_ref:\n",
                "    zip_ref.extractall(raw_dir)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "map",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
